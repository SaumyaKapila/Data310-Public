*Was your social distance detector effective at detecting potential violations?*
	My social distancing detector was fairly effective, clearly being able to highlight and track people as they walked across the screen, and provide updated data as to whether or not they were following the recommended 6-foot-apart rule that the CDC set for people spending time outside. Though the detector seemingly had almost no trouble in detecting people in the foreground and the midground of the video (save for the occasional pixelated group of people in the midground), it did have some difficulty when people were overlapping towards the background and places where the lighting did not allow for clear differences between outlines of separate people.


*Do you think this approach would be effective for estimating new infections in real time? How would you implement such an approach in response to the COVID-19 pandemic we are currently experiencing?*
	Though in theory, this detection method may seem like a great way to estimate new infections in real time, I feel as though this method may be too much in its early stages to provide accurate estimations and information to be used effectively. For one, the processing power required to analyze the short video that I provided it alone was a lot for my computer to handle, so thinking about an entire live streamed video feed constantly updating and attempting to generally analyze whether or not social distancing policies are being maintained seems like it would not be effective in the way people may think it would be. This is because of a few reasons: firstly, the the code utilized for this type of video analysis would have to be refined in such a way that it could be used in extremely dense populations for it to be effective at all- as one could see with the code provided, the small crowds of people in the midground of the clip as well as larger crowds in the background were completely ignored by the video analyzer. Secondly, the code did not take into account the wearing of masks by any persons in the video or the setting in which the video was taken (i.e. inside vs.outside). Research has shown that people who come into contact for very short amounts of time inside are much less likely to be infected with the virus, even if the person they did come into contact with was a carrier of COVID19, and even less likely to become infected if one or both of them was wearing a mask. Therefore, though in principle the video analyzer is a great idea for detecting new infections, in its current state I feel as though it would be better used for subsidiary research information.


*What limitations or improvements might you include in order to improve your proposed design?*
	Something to definitely consider when writing improving the code for future implementations would undoubtedly be the consideration of angles at which the cameras are placed at- since the camera is not going to be placed at a birdâ€™s eye view, two figures that are present on the screen may be further or closer than they may appear to be. Secondly, a limitation that is separate from how the analyzer is coded would be the quality of the video feed- obviously, if the quality of the video feed is higher, it will be much easier for the video analyzer to differentiate between people and thus provide better data. In conjunction with this, the consideration of price for the cameras must then also be considered, as well as the price for computers that would have higher processing power (with a higher definition video feed, more information and therefore more processing power would be required). Finally, as mentioned above, the presence of masks is a necessary piece of information to be able to consider. With all these improvements, the design would be much less flawed and thus much more effective for the detection of the spread of possible COVID19 infections.
